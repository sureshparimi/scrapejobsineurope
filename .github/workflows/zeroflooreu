name: Scrape latest jobs

on:
  push:
  workflow_dispatch:
  schedule:
    - cron: '0 */4 * * *'

jobs:
  job2:
    runs-on: ubuntu-latest

    steps:
      - name: Checking out repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      - name: Install necessary packages
        run: |
          pip install requests beautifulsoup4 pandas webdriver-manager selenium

      - name: Run the scraping script
        run: python scrape_latest_jobs.py || echo "Script failed,continuing workflow"

      - name: Parse ottacomdata.json into table
        id: parse-json
        run: |
          echo "# Latest Jobs" > README.md
          echo "" >> README.md
          echo "This page is updated at $(TZ='Europe/Paris' date +'%B %d, %Y %H:%M:%S')" >> README.md
          echo "" >> README.md
          echo "| Job Title | Job Location | Job Link | Job Posted |" >> README.md
          echo "| --- | --- | --- | --- |" >> README.md
          while IFS="|" read -r job_title job_location job_link job_posted; do
            echo "| $job_title | $job_location | [Apply]($job_link) | $job_posted |" >> README.md
          done < <(jq -r '.[] | "\(.job_title)|\(.job_location)|\(.JobLink)|\(.JobPosted // (now | strftime("%e %B %Y %l:%M %p %Z")))"' ottacomdata.json) || echo "JSON parsing failed"

      - name: Set Git user credentials
        run: |
          git config --global user.name "Suresh Parimi"
          git config --global user.email "reachparimi@gmail.com"

      - name: Pull changes from remote repository
        run: git pull

      - name: Commit and push if it changed
        run: |
          git add README.md
          timestamp=$(date -u)
          git commit -m "Latest jobs: ${timestamp}" || exit 0
          git push

  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checking out repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4 pandas selenium

      - name: Run the scraping script
        run: python relocatewithus.py || echo "Script failed, continuing workflow"

      - name: Parse relocatewithusjobs.json into table
        id: parse-json
        run: |
          echo "| Job Title | Job Location | Job Link | Job Posted | Visa Sponsorship |" > README.md
          echo "| --- | --- | --- | --- | --- |" >> README.md
          jq -r '.[] | "| \(.position) | \(.location) | [\(.description)](\(.description)) | \(.post_date) | \(.visa) |"' relocatewithusjobs.json >> README.md || echo "JSON parsing failed"

      - name: Set Git user credentials
        run: |
          git config --global user.name "Your Name"
          git config --global user.email "your-email@example.com"

      - name: Pull changes from remote repository
        run: git pull

      - name: Commit and push if it changed
        run: |
          git add README.md
          timestamp=$(date -u)
          git commit -m "Latest jobs: ${timestamp}" || exit 0
          git push
name: Scrape latest jobs

on:
  push:
  workflow_dispatch:
  schedule:
    - cron: '0 */4 * * *'

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checking out repo
        uses: actions/checkout@v3

      - name: Setting up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Installing necessary packages
        run: |
          apt list --installed
          sudo apt purge google-chrome-stable
          pip install chromedriver-autoinstaller selenium pyvirtualdisplay
          sudo apt-get install xvfb
          pip install requests beautifulsoup4 pandas webdriver-manager selenium

      - name: Run the scraping script
        run: python scratchpad.py || echo "Script failed, continuing workflow"

      - name: Parse ottacomdata.json into table
        id: parse-json
        run: |
          echo "# Latest Jobs" > README.md
          echo "" >> README.md
          echo "This page is updated at $(TZ='Europe/Paris' date +'%B %d, %Y %H:%M:%S')" >> README.md
          echo "" >> README.md
          echo "| Job Title | Job Location | Job Link | Job Posted |" >> README.md
          echo "| --- | --- | --- | --- |" >> README.md
          while IFS="|" read -r job_title job_location job_link job_posted; do
            echo "| $job_title | $job_location | [Apply]($job_link) | $job_posted |" >> README.md
          done < <(jq -r '.[] | "\(.job_title)|\(.job_location)|\(.JobLink)|\(.JobPosted // (now | strftime("%e %B %Y %l:%M %p %Z")))"' ottacomdata.json) || echo "JSON parsing failed"

      - name: Set Git user credentials
        run: |
          git config --global user.name "Suresh Parimi"
          git config --global user.email "reachparimi@gmail.com"

      - name: Pull changes from remote repository
        run: git pull

      - name: Commit and push if it changed
        run: |
          git add README.md
          timestamp=$(date -u)
          git commit -m "Latest jobs: ${timestamp}" || exit 0
          git push
