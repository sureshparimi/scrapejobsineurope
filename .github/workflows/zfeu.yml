name: Scrape and Archive Jobs

on:
  push:
  workflow_dispatch:
  schedule:
    - cron: '0 */4 * * *'

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      # Step 1: Check out the repository
      - name: Checking out repo
        uses: actions/checkout@v3

      # Step 2: Set up Python
      - name: Setting up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      # Step 3: Install necessary packages
      - name: Installing necessary packages
        run: |
          apt list --installed
          sudo apt purge google-chrome-stable
          pip install chromedriver-autoinstaller selenium pyvirtualdisplay
          sudo apt-get install xvfb
          pip install requests beautifulsoup4 pandas webdriver-manager selenium

      # Step 4: Run the scraping script
      - name: Run the scraping script
        run: python scratchpad.py || echo "Script failed, continuing workflow"

  archive:
    needs: scrape
    runs-on: ubuntu-latest
    steps:
      # Step 1: Check out the repository
      - name: Checking out repo
        uses: actions/checkout@v3

      # Step 2: Create the archivedjobs.md file
      - name: Create archivedjobs.md
        run: |
          echo "# Archived Jobs" > archivedjobs.md
          echo "" >> archivedjobs.md
          echo "| Job Title | Job Location | Job Link | Job Posted |" >> archivedjobs.md
          echo "| --- | --- | --- | --- |" >> archivedjobs.md
          jq -r '.[] | select(.job_title and .job_location and .JobLink and .JobPosted) | "\(.job_title)|\(.job_location)|\(.JobLink)|\(.JobPosted)"' masterdatabase.json | sed '/null/d' >> archivedjobs.md

      # Step 3: Set Git user credentials
      - name: Set Git user credentials
        run: |
          git config --global user.name "Suresh Parimi"
          git config --global user.email "reachparimi@gmail.com"

      # Step 4: Pull changes from the remote repository
      - name: Pull changes from remote repository
        run: git pull

      # Step 5: Commit and push the changes to archivedjobs.md
      - name: Commit and push if it changed
        run: |
          git add archivedjobs.md
          timestamp=$(date -u)
          git commit -m "Archived jobs: ${timestamp}" || exit 0
          git push

  copy_data:
    needs: archive
    runs-on: ubuntu-latest
    steps:
      # Step 1: Check out the repository
      - name: Checking out repo
        uses: actions/checkout@v3

      # Step 2: Validate and fix the format of alljobs.json
      - name: Validate and fix alljobs.json format
        run: |
          jq empty alljobs.json || jq -s '.' alljobs.json > temp.json && mv temp.json alljobs.json

      # Step 3: Copy masterdatabase.json to alljobs.json
      - name: Copy masterdatabase.json to alljobs.json
        run: |
          jq -c '.[] | select(.job_title and .job_location and .JobLink and .JobPosted)' masterdatabase.json >> alljobs.json

      # Step 4: Set Git user credentials
      - name: Set Git user credentials
        run: |
          git config --global user.name "Suresh Parimi"
          git config --global user.email "reachparimi@gmail.com"

      # Step 5: Pull changes from the remote repository
      - name: Pull changes from remote repository
        run: git pull

      # Step 6: Commit and push the changes to alljobs.json
      - name: Commit and push if it changed
        run: |
          git add alljobs.json
          timestamp=$(date -u)
          git commit -m "Update alljobs.json: ${timestamp}" || exit 0
          git push
